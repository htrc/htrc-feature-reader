{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tempfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from htrc_features import Volume\n",
    "efpaths = glob.glob('/home/peter.organisciak/htrc-feature-reader/data/PZ-volumes/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>section</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">body</th>\n",
       "      <th>On</th>\n",
       "      <th>IN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serao</th>\n",
       "      <th>NN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <th>DT</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <th>CC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ballet</th>\n",
       "      <th>NN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count\n",
       "page section token  pos       \n",
       "1    body    On     IN       1\n",
       "             Serao  NN       1\n",
       "             The    DT       1\n",
       "             and    CC       1\n",
       "             ballet NN       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdir = tempfile.TemporaryDirectory()\n",
    "rewritedir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Write basic EF files to temp dir\n",
    "for path in efpaths:\n",
    "    vol = Volume(path)\n",
    "    vol.save_parquet(tdir.name, meta=False)\n",
    "ogpaths = glob.glob(tdir.name+'/*')\n",
    "pd.read_parquet(ogpaths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OG Size: 3.37M'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def statdir(name, dirname):\n",
    "    size= sum(os.path.getsize(f) for f in glob.glob(dirname+'/*'))\n",
    "    return \"{} Size: {:.2f}M\".format(name, (size / 1024**2))\n",
    "statdir(\"OG\", tdir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size Comparisons\n",
    "\n",
    "Pyarrow rewrite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow Size: 3.37M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>section</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">body</th>\n",
       "      <th>On</th>\n",
       "      <th>IN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serao</th>\n",
       "      <th>NN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count\n",
       "page section token pos       \n",
       "1    body    On    IN       1\n",
       "             Serao NN       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path in ogpaths:\n",
    "    df = pd.read_parquet(path)\n",
    "    df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "print(statdir(\"pyarrow\", rewritedir.name))\n",
    "pd.read_parquet(glob.glob(rewritedir.name+'/*')[0]).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite with *fastparquet*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastparquet Size: 6.80M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>section</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">body</th>\n",
       "      <th>On</th>\n",
       "      <th>IN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serao</th>\n",
       "      <th>NN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count\n",
       "page section token pos       \n",
       "1    body    On    IN       1\n",
       "             Serao NN       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path in ogpaths:\n",
    "    df = pd.read_parquet(path)\n",
    "    df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='fastparquet')\n",
    "print(statdir(\"fastparquet\", rewritedir.name))\n",
    "pd.read_parquet(glob.glob(rewritedir.name+'/*')[0]).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No index / PyArrow  Size: 3.37M\n"
     ]
    }
   ],
   "source": [
    "for path in ogpaths:\n",
    "    df = pd.read_parquet(path).reset_index()\n",
    "    df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "print(statdir(\"No index / PyArrow \", rewritedir.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted index Size: 3.37M\n"
     ]
    }
   ],
   "source": [
    "for path in ogpaths:\n",
    "    df = pd.read_parquet(path).sort_index()\n",
    "    df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "print(statdir(\"sorted index\", rewritedir.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted By section,pos/count/token / PyArrow  Size: 2.52M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>body</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>body</td>\n",
       "      <td>\"</td>\n",
       "      <td>''</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>body</td>\n",
       "      <td>\"</td>\n",
       "      <td>''</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>body</td>\n",
       "      <td>\"</td>\n",
       "      <td>''</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>body</td>\n",
       "      <td>\"</td>\n",
       "      <td>''</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     section token pos  count\n",
       "page                         \n",
       "59      body     #   #      1\n",
       "44      body     \"  ''      1\n",
       "45      body     \"  ''      1\n",
       "48      body     \"  ''      1\n",
       "82      body     \"  ''      1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path in ogpaths:\n",
    "    df = (pd.read_parquet(path).reset_index()\n",
    "          .sort_values(['section', 'pos', 'count', 'token']).set_index(['page'])\n",
    "         )\n",
    "    df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "print(statdir(\"Sorted By section,pos/count/token / PyArrow \", rewritedir.name))\n",
    "pd.read_parquet(glob.glob(rewritedir.name+'/*')[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of sorting on compression size (*snappy*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page,section,token,pos Size: 3.37M\n",
      "page,section,pos,token Size: 2.97M\n",
      "page,token,section,pos Size: 3.38M\n",
      "page,token,pos,section Size: 3.38M\n",
      "page,pos,section,token Size: 2.99M\n",
      "page,pos,token,section Size: 2.99M\n",
      "section,page,token,pos Size: 3.37M\n",
      "section,page,pos,token Size: 2.97M\n",
      "section,token,page,pos Size: 2.85M\n",
      "section,token,pos,page Size: 2.77M\n",
      "section,pos,page,token Size: 2.97M\n",
      "section,pos,token,page Size: 2.65M\n",
      "token,page,section,pos Size: 2.85M\n",
      "token,page,pos,section Size: 2.85M\n",
      "token,section,page,pos Size: 2.84M\n",
      "token,section,pos,page Size: 2.77M\n",
      "token,pos,page,section Size: 2.77M\n",
      "token,pos,section,page Size: 2.77M\n",
      "pos,page,section,token Size: 2.99M\n",
      "pos,page,token,section Size: 3.00M\n",
      "pos,section,page,token Size: 2.96M\n",
      "pos,section,token,page Size: 2.66M\n",
      "pos,token,page,section Size: 2.67M\n",
      "pos,token,section,page Size: 2.67M\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for perm in itertools.permutations(['page', 'section', 'token', 'pos']):\n",
    "    for path in ogpaths:\n",
    "        df = pd.read_parquet(path).reorder_levels(perm).sort_index()\n",
    "        df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "    print(statdir(\",\".join(perm), rewritedir.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page,token,pos Size: 3.35M\n",
      "page,pos,token Size: 2.95M\n",
      "token,page,pos Size: 2.83M\n",
      "token,pos,page Size: 2.76M\n",
      "pos,page,token Size: 2.96M\n",
      "pos,token,page Size: 2.66M\n"
     ]
    }
   ],
   "source": [
    "for perm in itertools.permutations(['page', 'token', 'pos']):\n",
    "    for path in ogpaths:\n",
    "        df = pd.read_parquet(path).reset_index().groupby(list(perm))[['count']].sum().sort_index()\n",
    "        df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "    print(statdir(\",\".join(perm), rewritedir.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page,token Size: 2.70M\n",
      "token,page Size: 2.53M\n"
     ]
    }
   ],
   "source": [
    "for perm in itertools.permutations(['page', 'token']):\n",
    "    for path in ogpaths:\n",
    "        df = pd.read_parquet(path).reset_index().groupby(list(perm))[['count']].sum().sort_index()\n",
    "        df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "    print(statdir(\",\".join(perm), rewritedir.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size with `section='body'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just body: page,section,token Size: 2.65M\n",
      "Just body: page,token,section Size: 2.65M\n",
      "Just body: section,page,token Size: 2.65M\n",
      "Just body: section,token,page Size: 2.49M\n",
      "Just body: token,page,section Size: 2.49M\n",
      "Just body: token,section,page Size: 2.49M\n"
     ]
    }
   ],
   "source": [
    "for perm in itertools.permutations(['page', 'section', 'token']):\n",
    "    for path in ogpaths:\n",
    "        df = pd.read_parquet(path).reset_index().query(\"section=='body'\").groupby(list(perm))[['count']].sum().sort_index()\n",
    "        df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "    print(statdir(\"Just body: \" + \",\".join(perm), rewritedir.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just body: page,token Size: 2.64M\n",
      "Just body: token,page Size: 2.48M\n"
     ]
    }
   ],
   "source": [
    "for perm in itertools.permutations(['page', 'token']):\n",
    "    for path in ogpaths:\n",
    "        df = pd.read_parquet(path).reset_index().query(\"section=='body'\").groupby(list(perm))[['count']].sum().sort_index()\n",
    "        df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "    print(statdir(\"Just body: \" + \",\".join(perm), rewritedir.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size with `case=False`\n",
    "\n",
    "Resaving OG volumes with `section='body', drop_section=True, case=False` token_kwargs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>and</th>\n",
       "      <th>CC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ballet</th>\n",
       "      <th>NN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count\n",
       "page lowercase pos       \n",
       "1    and       CC       1\n",
       "     ballet    NN       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerdir = tempfile.TemporaryDirectory()\n",
    "for path in efpaths:\n",
    "    vol = Volume(path)\n",
    "    vol.save_parquet(lowerdir.name, meta=False, token_kwargs=dict(section='body', drop_section=True, case=False))\n",
    "lowerpaths = glob.glob(lowerdir.name+'/*')\n",
    "pd.read_parquet(lowerpaths[0]).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page,lowercase,pos Size: 3.15M\n",
      "page,pos,lowercase Size: 2.77M\n",
      "lowercase,page,pos Size: 2.68M\n",
      "lowercase,pos,page Size: 2.60M\n",
      "pos,page,lowercase Size: 2.77M\n",
      "pos,lowercase,page Size: 2.50M\n"
     ]
    }
   ],
   "source": [
    "for perm in itertools.permutations(['page', 'lowercase', 'pos']):\n",
    "    for path in lowerpaths:\n",
    "        df = pd.read_parquet(path).reset_index().groupby(list(perm))[['count']].sum().sort_index()\n",
    "        df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "    print(statdir(\",\".join(perm), rewritedir.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size comparison without `reset_index`\n",
    "\n",
    "Should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page,lowercase,pos Size: 3.15M\n",
      "page,pos,lowercase Size: 2.77M\n",
      "lowercase,page,pos Size: 2.68M\n",
      "lowercase,pos,page Size: 2.60M\n",
      "pos,page,lowercase Size: 2.77M\n",
      "pos,lowercase,page Size: 2.50M\n"
     ]
    }
   ],
   "source": [
    "for perm in itertools.permutations(['page', 'lowercase', 'pos']):\n",
    "    for path in lowerpaths:\n",
    "        df = pd.read_parquet(path).reorder_levels(perm).sort_index()\n",
    "        df.to_parquet(os.path.join(rewritedir.name, os.path.split(path)[1]), engine='pyarrow')\n",
    "    print(statdir(\",\".join(perm), rewritedir.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- speed of reorder_levels>sort_index vs reset_index>sort_values>set_index\n",
    "- speed cost of reading and sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speed cost of reading and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page,token,pos Size: 3.35M Reading time: 0.34s\n",
      "page,pos,token Size: 2.95M Reading+Sorting time: 1.14s\n",
      "token,page,pos Size: 2.83M Reading+Sorting time: 1.09s\n",
      "token,pos,page Size: 2.76M Reading+Sorting time: 1.09s\n",
      "pos,page,token Size: 2.96M Reading+Sorting time: 1.13s\n",
      "pos,token,page Size: 2.66M Reading+Sorting time: 1.13s\n"
     ]
    }
   ],
   "source": [
    "preferred_order = ['page', 'token', 'pos']\n",
    "for perm in itertools.permutations(['page', 'token', 'pos']):\n",
    "    totaltime = 0\n",
    "    for path in ogpaths:\n",
    "        df = pd.read_parquet(path).reset_index().groupby(list(perm))[['count']].sum().sort_index()\n",
    "        outpath = os.path.join(rewritedir.name, os.path.split(path)[1])\n",
    "        df.to_parquet(outpath, engine='pyarrow')\n",
    "        # Measure read and sort-if-necessary times\n",
    "        starttime = time.time()\n",
    "        df = pd.read_parquet(outpath)\n",
    "        if df.index.names != preferred_order:\n",
    "            # fastest\n",
    "            df = df.reorder_levels(preferred_order).sort_index()\n",
    "            # alt\n",
    "            #df = df.reset_index().set_index(preferred_order).sort_index()\n",
    "            # potentially faster, but not sure yet if there's a downstream performance hit\n",
    "            #df = df.reset_index().sort_values(preferred_order).set_index(preferred_order)\n",
    "        totaltime += (time.time() - starttime)\n",
    "    if list(perm) == preferred_order:\n",
    "        print(statdir(\",\".join(perm), rewritedir.name), \"Reading time: {:.2f}s\".format(totaltime))\n",
    "    else:\n",
    "        print(statdir(\",\".join(perm), rewritedir.name), \"Reading+Sorting time: {:.2f}s\".format(totaltime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### size and speed of reorder_levels>sort_index vs reset_index>sort_values>set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset_index \t page,section,token,pos Size: 3.37M Sorting Time: 0.39s\n",
      "reorder_levels \t page,section,token,pos Size: 3.37M Sorting Time: 1.82s\n",
      "reset_index \t page,section,pos,token Size: 2.97M Sorting Time: 0.43s\n",
      "reorder_levels \t page,section,pos,token Size: 2.97M Sorting Time: 0.99s\n",
      "reset_index \t page,token,section,pos Size: 3.38M Sorting Time: 0.40s\n",
      "reorder_levels \t page,token,section,pos Size: 3.38M Sorting Time: 0.99s\n"
     ]
    }
   ],
   "source": [
    "for perm in list(itertools.permutations(['page', 'section', 'token', 'pos']))[:3]:\n",
    "    perm = list(perm)\n",
    "    for strategy in ('reset_index', 'reorder_levels'):\n",
    "        totaltime = 0\n",
    "        for path in ogpaths:\n",
    "            df = pd.read_parquet(path)\n",
    "            starttime = time.time()\n",
    "            if strategy == 'reset_index':\n",
    "                df = df.reset_index().sort_values(perm).set_index(perm[0])\n",
    "            elif strategy == 'reorder_levels':\n",
    "                df = df.reorder_levels(perm).sort_index()\n",
    "            totaltime += (time.time() - starttime)\n",
    "            \n",
    "            outpath = os.path.join(rewritedir.name, os.path.split(path)[1])\n",
    "            df.to_parquet(outpath, engine='pyarrow')        \n",
    "        print(strategy, '\\t', statdir(\",\".join(perm), rewritedir.name), \"Sorting Time: {:.2f}s\".format(totaltime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
